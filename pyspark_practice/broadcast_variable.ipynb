{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f1985a8-886f-4c8a-a735-1fef309ac48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+------+--------+------------+\n",
      "|Store_Id|      Item|Amount|Store_Id|  Store_name|\n",
      "+--------+----------+------+--------+------------+\n",
      "|       1|  Cosmetic|   150|       1|Store_london|\n",
      "|       2|Stationary|   250|       2|   Store_nyc|\n",
      "|       3|   Apparel|   180|       3| Store_paris|\n",
      "|       4|      Food|   500|       4|    Store_LA|\n",
      "|       5|   Leisure|   300|       5| Store_swiss|\n",
      "|       1|       Deo|   100|       1|Store_london|\n",
      "|       2|     Books|   200|       2|   Store_nyc|\n",
      "|       3|   Tshirts|   120|       3| Store_paris|\n",
      "|       4|   Burgers|   200|       4|    Store_LA|\n",
      "|       5|     Movie|   180|       5| Store_swiss|\n",
      "+--------+----------+------+--------+------------+\n",
      "\n",
      "== Parsed Logical Plan ==\n",
      "Join Inner, (Store_Id#295 = Store_Id#318)\n",
      ":- Relation [Store_Id#295,Item#296,Amount#297] csv\n",
      "+- ResolvedHint (strategy=broadcast)\n",
      "   +- Relation [Store_Id#318,Store_name#319] csv\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "Store_Id: int, Item: string, Amount: int, Store_Id: int, Store_name: string\n",
      "Join Inner, (Store_Id#295 = Store_Id#318)\n",
      ":- Relation [Store_Id#295,Item#296,Amount#297] csv\n",
      "+- ResolvedHint (strategy=broadcast)\n",
      "   +- Relation [Store_Id#318,Store_name#319] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Join Inner, (Store_Id#295 = Store_Id#318), rightHint=(strategy=broadcast)\n",
      ":- Filter isnotnull(Store_Id#295)\n",
      ":  +- Relation [Store_Id#295,Item#296,Amount#297] csv\n",
      "+- Filter isnotnull(Store_Id#318)\n",
      "   +- Relation [Store_Id#318,Store_name#319] csv\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- BroadcastHashJoin [Store_Id#295], [Store_Id#318], Inner, BuildRight, false\n",
      "   :- Filter isnotnull(Store_Id#295)\n",
      "   :  +- FileScan csv [Store_Id#295,Item#296,Amount#297] Batched: false, DataFilters: [isnotnull(Store_Id#295)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/C:/Users/HP/pythonlab/Scripts/pyspark_practice/products.csv], PartitionFilters: [], PushedFilters: [IsNotNull(Store_Id)], ReadSchema: struct<Store_Id:int,Item:string,Amount:int>\n",
      "   +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=372]\n",
      "      +- Filter isnotnull(Store_Id#318)\n",
      "         +- FileScan csv [Store_Id#318,Store_name#319] Batched: false, DataFilters: [isnotnull(Store_Id#318)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/C:/Users/HP/pythonlab/Scripts/pyspark_practice/stores.csv], PartitionFilters: [], PushedFilters: [IsNotNull(Store_Id)], ReadSchema: struct<Store_Id:int,Store_name:string>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#BROADCAST VARIABLE: Through this feature, we are able to save copy of data in each node\n",
    "\n",
    "import pyspark, os, sys\n",
    "from pyspark.sql import *\n",
    "from pyspark import SparkConf,SparkContext\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import types\n",
    "from pyspark import StorageLevel\n",
    "from pyspark.sql.functions import broadcast\n",
    "\n",
    "spark=SparkSession.builder.getOrCreate()\n",
    "\n",
    "transactionDF=spark.read.format(\"csv\").option(\"inferSchema\", True).option(\"header\", True).load(\"products.csv\")\n",
    "\n",
    "#transactionDF.show()\n",
    "\n",
    "#transactionDF.printSchema()\n",
    "\n",
    "storesDF=spark.read.format(\"csv\").option(\"inferSchema\", True).option(\"header\", True).load(\"stores.csv\")\n",
    "\n",
    "#storesDF.show()\n",
    "\n",
    "joinDF=transactionDF.join(broadcast(storesDF), transactionDF.Store_Id==storesDF.Store_Id) # here are putting data of storesDF in all the nodes.\n",
    "\n",
    "joinDF.show()\n",
    "\n",
    "joinDF.explain(True)  #to check the execution of the dataframe  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15a1d34-cb11-45dc-8a45-2de2d74d00cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

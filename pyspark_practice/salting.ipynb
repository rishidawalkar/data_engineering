{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d3efcd6-8a81-4ab3-b453-97c4a0d190f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+----------+--------+----------+------+---------+---------------+-----------+\n",
      "|store_id|store_name|salt_value|store_id|product_id|amount| sequence|exploded_values|salt_value2|\n",
      "+--------+----------+----------+--------+----------+------+---------+---------------+-----------+\n",
      "|     101|   Walmart|     101_0|     101|      P001|   100|[0, 1, 2]|              0|      101_0|\n",
      "|     101|   Walmart|     101_0|     101|      P002|   200|[0, 1, 2]|              0|      101_0|\n",
      "|     101|   Walmart|     101_0|     101|      P003|   150|[0, 1, 2]|              0|      101_0|\n",
      "|     102|    Target|     102_0|     102|      P004|   300|[0, 1, 2]|              0|      102_0|\n",
      "|     103|    Costco|     103_0|     103|      P005|   400|[0, 1, 2]|              0|      103_0|\n",
      "|     101|   Walmart|     101_0|     101|      P006|   500|[0, 1, 2]|              0|      101_0|\n",
      "|     104|   BestBuy|     104_0|     104|      P007|   250|[0, 1, 2]|              0|      104_0|\n",
      "+--------+----------+----------+--------+----------+------+---------+---------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark, os, sys\n",
    "from pyspark.sql import *\n",
    "from pyspark import SparkConf,SparkContext\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import types\n",
    "from pyspark import StorageLevel\n",
    "from pyspark.sql.functions import broadcast\n",
    "from pyspark.sql.functions import instr\n",
    "from pyspark.sql.functions import expr\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import regexp_extract\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "from pyspark.sql.functions import posexplode\n",
    "from pyspark.sql.functions import spark_partition_id\n",
    "from pyspark.sql.functions import substring\n",
    "from pyspark.sql.functions import array_contains\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "spark=SparkSession.builder.getOrCreate()\n",
    "\n",
    "store_df=spark.read.format(\"csv\").option(\"header\", True).load(\"stores.csv\")\n",
    "\n",
    "sales_df=spark.read.format(\"csv\").option(\"header\", True).load(\"sales.csv\")\n",
    "\n",
    "store_df=store_df.withColumn(\"salt_value\", concat(\"store_id\", lit(\"_\"), (rand()*0).cast(\"Integer\")))\n",
    "#store_df.show()\n",
    "\n",
    "sales_df=sales_df.withColumn(\"sequence\", array([lit(i) for i in range(0,3)]))\n",
    "sales_df=sales_df.withColumn(\"exploded_values\", explode(\"sequence\"))\n",
    "\n",
    "sales_df=sales_df.withColumn(\"salt_value2\", concat(\"store_id\", lit(\"_\"), \"exploded_values\"))\n",
    "#sales_df.show()\n",
    "\n",
    "join_df=store_df.join(sales_df, store_df.salt_value==sales_df.salt_value2, \"inner\")\n",
    "join_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9592c9-acce-4ff2-aab1-5f866f54ee72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

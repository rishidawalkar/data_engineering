{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dafe08e2-0a4b-4e50-87a5-bc9c5c9a3cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+----+----+----------+------+--------+--------+--------+--------+----------+----------+-----------+\n",
      "|  id|dim1|dim2|dim3|dim4|  new_hash|id_old|dim1_old|dim2_old|dim3_old|dim4_old|   st_date|  end_date|   old_hash|\n",
      "+----+----+----+----+----+----------+------+--------+--------+--------+--------+----------+----------+-----------+\n",
      "| 111| 200| 500| 800| 400|-842040841|   111|     200|     500|     800|     400|2024-12-01|2999-12-31| -842040841|\n",
      "| 222| 800|1300| 800| 500| 307381462|   222|     900|    NULL|     700|     100|2024-12-01|2999-12-31|-1540894174|\n",
      "|NULL|NULL|NULL|NULL|NULL|      NULL|   333|     300|     900|     250|     650|2024-12-01|2999-12-31|-1529515503|\n",
      "| 444| 100|NULL| 700| 300|-805886361|  NULL|    NULL|    NULL|    NULL|    NULL|      NULL|      NULL|       NULL|\n",
      "+----+----+----+----+----+----------+------+--------+--------+--------+--------+----------+----------+-----------+\n",
      "\n",
      "+------+--------+--------+--------+--------+\n",
      "|id_old|dim1_old|dim2_old|dim3_old|dim4_old|\n",
      "+------+--------+--------+--------+--------+\n",
      "|   111|     200|     500|     800|     400|\n",
      "|   333|     300|     900|     250|     650|\n",
      "+------+--------+--------+--------+--------+\n",
      "\n",
      "+---+----+----+----+----+\n",
      "| id|dim1|dim2|dim3|dim4|\n",
      "+---+----+----+----+----+\n",
      "|444| 100|NULL| 700| 300|\n",
      "+---+----+----+----+----+\n",
      "\n",
      "+---+----+----+----+----+\n",
      "| id|dim1|dim2|dim3|dim4|\n",
      "+---+----+----+----+----+\n",
      "|222| 800|1300| 800| 500|\n",
      "+---+----+----+----+----+\n",
      "\n",
      "final SCD result:\n",
      "+------+--------+--------+--------+--------+\n",
      "|id_old|dim1_old|dim2_old|dim3_old|dim4_old|\n",
      "+------+--------+--------+--------+--------+\n",
      "|   111|     200|     500|     800|     400|\n",
      "|   333|     300|     900|     250|     650|\n",
      "|   444|     100|    NULL|     700|     300|\n",
      "|   222|     800|    1300|     800|     500|\n",
      "+------+--------+--------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark, os, sys\n",
    "from pyspark.sql import *\n",
    "from pyspark import SparkConf,SparkContext\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import types\n",
    "from pyspark import StorageLevel\n",
    "from pyspark.sql.functions import broadcast\n",
    "from pyspark.sql.functions import hash\n",
    "\n",
    "spark=SparkSession.builder.getOrCreate()\n",
    "\n",
    "#####################First Method###################################\n",
    "df_new=spark.read.format(\"csv\").option(\"header\", True).load(\"new.csv\")\n",
    "\n",
    "df_old=spark.read.format(\"csv\").option(\"header\", True).load(\"old.csv\")\n",
    "df_old=df_old.withColumn(\"st_date\", col(\"st_date\").cast(\"date\"))\\\n",
    "            .withColumn(\"end_date\", col(\"end_date\").cast(\"date\"))\n",
    "\n",
    "df_new=df_new.withColumn(\"id\", col(\"id\").cast(\"int\"))\\\n",
    "            .withColumn(\"dim1\", col(\"dim1\").cast(\"int\"))\\\n",
    "            .withColumn(\"dim2\", col(\"dim2\").cast(\"int\"))\\\n",
    "            .withColumn(\"dim3\", col(\"dim3\").cast(\"int\"))\\\n",
    "            .withColumn(\"dim4\", col(\"dim4\").cast(\"int\"))\\\n",
    "            .withColumn(\"new_hash\", hash(\"id\", \"dim1\", \"dim2\", \"dim3\", \"dim4\"))  #to compare with old records\n",
    "\n",
    "df_old=df_old.withColumn(\"id_old\", col(\"id_old\").cast(\"int\"))\\\n",
    "            .withColumn(\"dim1_old\", col(\"dim1_old\").cast(\"int\"))\\\n",
    "            .withColumn(\"dim2_old\", col(\"dim2_old\").cast(\"int\"))\\\n",
    "            .withColumn(\"dim3_old\", col(\"dim3_old\").cast(\"int\"))\\\n",
    "            .withColumn(\"dim4_old\", col(\"dim4_old\").cast(\"int\"))\\\n",
    "            .withColumn(\"old_hash\", hash(\"id_old\", \"dim1_old\", \"dim2_old\", \"dim3_old\", \"dim4_old\"))  #to compare with new records\n",
    "\n",
    "\n",
    "join_df=df_new.join(df_old, df_new.id==df_old.id_old, \"full\")\n",
    "join_df.show()\n",
    "\n",
    "unchanged_df=join_df.filter((col(\"new_hash\")==col(\"old_hash\"))|(col(\"new_hash\").isNull()))\\\n",
    "                    .select(\"id_old\", \"dim1_old\", \"dim2_old\", \"dim3_old\", \"dim4_old\")  #row with no changes\n",
    "unchanged_df.show()\n",
    "\n",
    "new_changes_df=join_df.filter(col(\"old_hash\").isNull()).select(\"id\", \"dim1\", \"dim2\", \"dim3\", \"dim4\")  #new row\n",
    "new_changes_df.show()\n",
    "\n",
    "updated_df=join_df.filter(col(\"new_hash\")!=col(\"old_hash\")).select(\"id\", \"dim1\", \"dim2\", \"dim3\", \"dim4\")  #row with updated changes\n",
    "updated_df.show()\n",
    "\n",
    "print(\"final SCD result:\")\n",
    "final_df=unchanged_df.union(new_changes_df).union(updated_df)\n",
    "final_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd59e44-7033-4d1f-8a98-b800b2209150",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################Second Method################################\n",
    "\n",
    "old_df=spark.read.format(\"csv\").option(\"header\", True).load(\"customer_dim.csv\")\n",
    "\n",
    "new_df=spark.read.format(\"csv\").option(\"header\", True).load(\"customer_staging.csv\")\n",
    "\n",
    "old_df=old_df.withColumn(\"old_hash\", hash(\"customer_id\", \"customer_name\", \"city\"))\\\n",
    "            .withColumnRenamed(\"customer_id\", \"old_id\")\\\n",
    "            .withColumnRenamed(\"customer_name\", \"old_name\")\\\n",
    "            .withColumnRenamed(\"city\", \"old_city\")\n",
    "\n",
    "new_df=new_df.withColumn(\"new_hash\", hash(\"customer_id\", \"customer_name\", \"city\"))\\\n",
    "            .withColumnRenamed(\"customer_id\", \"new_id\")\\\n",
    "            .withColumnRenamed(\"customer_name\", \"new_name\")\\\n",
    "            .withColumnRenamed(\"city\", \"new_city\")\n",
    "\n",
    "join_df=new_df.join(old_df, new_df.new_id==old_df.old_id, \"full\")\n",
    "join_df.show()\n",
    "\n",
    "#no changes in data\n",
    "df1=join_df.filter((col(\"old_hash\")==col(\"new_hash\")) | (col(\"new_hash\").isNull()))\\\n",
    "    .select(\"old_id\", \"old_name\", \"old_city\", \"start_date\", \"end_date\", \"current_flag\")\n",
    "\n",
    "#updated changes in data\n",
    "df2=join_df.filter(col(\"old_hash\")!=col(\"new_hash\"))\\\n",
    "    .select(\"new_id\", \"new_name\", \"new_city\", \"start_date\", \"end_date\", \"current_flag\")\n",
    "\n",
    "#new data\n",
    "df3=join_df.filter(col(\"old_hash\").isNull())\\\n",
    "    .select(\"new_id\", \"new_name\", \"new_city\", \"start_date\", \"end_date\", \"current_flag\")\n",
    "\n",
    "df3=df3.withColumn(\"start_date\", current_date())\\\n",
    "        .withColumn(\"end_date\", lit(\"9999-12-31\"))\\\n",
    "        .withColumn(\"current_flag\", lit(\"Y\"))\n",
    "\n",
    "union_df=df1.union(df2).union(df3)\n",
    "union_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4261931a-b67c-429a-84c6-da5aa0c067b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################THIRD Method#############################\n",
    "\n",
    "spark=SparkSession.builder.getOrCreate()\n",
    "\n",
    "old_df=spark.read.format(\"csv\").option(\"header\", True).load(\"sample_scd.csv\")\n",
    "\n",
    "new_df=spark.read.format(\"csv\").option(\"header\", True).load(\"sample_scd2.csv\")\n",
    "\n",
    "old_df=old_df.withColumn(\"start_date\", col(\"start_date\").cast(\"date\"))\\\n",
    "            .withColumn(\"end_date\", col(\"end_date\").cast(\"date\"))\\\n",
    "            .withColumn(\"salary\", col(\"salary\").cast(\"Integer\"))\n",
    "\n",
    "new_df=new_df.withColumn(\"salary\", col(\"salary\").cast(\"Integer\"))\n",
    "\n",
    "new_df=new_df.withColumnRenamed(\"id\", \"id_new\")\\\n",
    "            .withColumnRenamed(\"name\", \"name_new\")\\\n",
    "            .withColumnRenamed(\"salary\", \"salary_new\")\n",
    "\n",
    "old_df=old_df.withColumn(\"hash_old\", hash(\"id\", \"name\", \"salary\"))\n",
    "new_df=new_df.withColumn(\"hash_new\", hash(\"id_new\", \"name_new\", \"salary_new\"))\n",
    "\n",
    "join_df=old_df.join(new_df, old_df.id==new_df.id_new, \"full\")\n",
    "#join_df.show()\n",
    "\n",
    "#unchanged\n",
    "print(\"unchanged\")\n",
    "df1=join_df.filter(col(\"hash_new\")==col(\"hash_old\"))\n",
    "df1=df1.select(\"id\", \"name\", \"salary\", \"start_date\", \"end_date\")\n",
    "df1.show()\n",
    "\n",
    "#new\n",
    "print(\"new\")\n",
    "df2=join_df.filter(col(\"hash_old\").isNull())\n",
    "df2=df2.select(\"id_new\", \"name_new\", \"salary_new\")\\\n",
    "        .withColumn(\"start_date\", current_date())\\\n",
    "        .withColumn(\"end_date\", lit(\"2999-12-31\").cast(\"date\"))\n",
    "df2.show()\n",
    "\n",
    "#updated\n",
    "print(\"updated\")\n",
    "df3=join_df.filter(col(\"hash_old\")!=col(\"hash_new\"))\n",
    "df3_a=df3.select(\"id\", \"name\", \"salary\", \"start_date\", \"end_date\")\\\n",
    "        .withColumn(\"end_date\", current_date()-1)\n",
    "df3_a.show()\n",
    "\n",
    "df3_b=df3.select(\"id_new\", \"name_new\", \"salary_new\")\\\n",
    "        .withColumn(\"start_date\", current_date())\\\n",
    "        .withColumn(\"end_date\", lit(\"2999-12-31\").cast(\"date\"))\n",
    "df3_b.show()\n",
    "\n",
    "print(\"final SCD2 result:\")\n",
    "final_df=df1.union(df2)\\\n",
    "            .union(df3_a)\\\n",
    "            .union(df3_b)\n",
    "final_df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
